summary( model1 <- glm( Edge_BN ~ R, Uttaran_data, family="binomial" ) )$coefficients
exp( coef(model1) ) /  ( 1 + exp( coef(model1) ) )
Uttaran_data$R_Binary <- factor( ifelse( Uttaran_data$R==1, "Day1", "Day2" ) )
xtabs(~R_Binary+Edge_BN, Uttaran_data)[,2] / xtabs(~R_Binary, Uttaran_data)
# Basic modelling
summary( model1 <- glm( Edge_BN ~ R_Binary, Uttaran_data, family="binomial" ) )$coefficients
exp( coef(model1) ) /  ( 1 + exp( coef(model1) ) )
# Show the proportions for each day
xtabs(~R+Edge_BN, Uttaran_data)[,2] / xtabs(~R, Uttaran_data)
# The predicted value for this condition: the intercept, plus the dummy coefficient for this condition
Yhat_day2 <- coef(model1)["(Intercept)"]
# Converting the predicted value from log odds into percentage
exp( Yhat_day2 ) / ( 1 + exp( Yhat_day2 ) )
# A logistic model: probability of being at the edge, as a function of Selection Line aka T
summary( model2 <- glm( Edge_Binary ~ T, Uttaran_data, family="binomial" ) )$coefficients
plot( Uttaran_data$T, jitter(ifelse( Uttaran_data$Edge_Binary=="yes",1,0 ),.1), pch=20, xlab="T", ylab="Likelihood of going to edge" )
# Inverse logit function
inverselogit <- function(x){ exp(x) / (1+exp(x) ) }
# Get the unique gpas
New_T <- sort( unique( Uttaran_data$T ) )
# Plot the model prediction for each GPA, with a line through them
lines( New_T, inverselogit( coef(model2)["(Intercept)"] + New_T*coef(model2)["T"] ), type="o", pch=22, bg="blue", cex=2 )
mod <- rpt(Edge_BN ~ 1 + (1|R) + ID, grname = "R", data = Uttaran_data, datatype = "Binary", link = "logit", CI = 0.95,
nboot = 1, npermut = 1, parallel = FALSE, ncores = NULL, ratio = TRUE, adjusted = TRUE, expect = "meanobs", rptObj = NULL,
update = FALSE)
library("ggplot2")
library("data.table")
library("ggrepel")
library("reshape2")
library("cowplot")
library("Rmisc")
library("dplyr")
library("stringr")
library("tidyr")
library("hexbin")
library("graphics")
library("readr")
library("splines") # Used for the ns() function â€” (natural cubic splines)
library("rptR")
library("readxl")
library("lme4")
library("GGally")
library("compiler")
library("parallel")
library("boot")
library("lattice")
library("aod")
options(digits = 10)
mod <- rpt(Edge_BN ~ 1 + (1|R) + ID, grname = "R", data = Uttaran_data, datatype = "Binary", link = "logit", CI = 0.95,
nboot = 1, npermut = 1, parallel = FALSE, ncores = NULL, ratio = TRUE, adjusted = TRUE, expect = "meanobs", rptObj = NULL,
update = FALSE)
library(MCMCglmm)
data <- read.table("GBAOF_Count.csv", sep = ";", head = T)
summary(data)
data$S <- as.factor(data$S)
data.na <- read.table("GBAOF_Count_NA.csv", sep = ",", head = T)
summary(data.na)
data.na$S <- as.factor(data.na$S)
data.na$R <- as.factor(data.na$R)
getwd()
setwd("~/Documents/GitHub/IODS-project")
getwd()
# Read Data
analysis <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt",
sep="\t", header=TRUE)
# Name - Shabbeer Hassan
# Date - 11 Nov 2018
# This is the week 2 work in the IODS course.
# Read Data
analysis <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt",
sep="\t", header=TRUE)
# Output from above
#
str(analysis)
dim(analysis)
##### Create an analysis dataset #####
library(dplyr)
# Choose the listed variables to keep
keep_columns <- c("gender","Age","attitude", "deep", "stra", "surf", "Points")
# Select the 'keep_columns' to create analysis dataset
analysis <- select(data1, one_of(keep_columns))
# Name - Shabbeer Hassan
# Date - 11 Nov 2018
# This is the week 2 work in the IODS course.
##### Read Data #####
data1 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt",
sep="\t", header=TRUE)
# Output from above
# str(data1)
# The output from above is the total number of observations (183 obs)
# and  total variables (n = 60)
# dim(data1)
# [1] 183  60
# The above tells us that data1 has 183 rows and 60 columns
##### Create an analysis dataset #####
library(dplyr)
# Choose the listed variables to keep
keep_columns <- c("gender","Age","attitude", "deep", "stra", "surf", "Points")
# Select the 'keep_columns' to create analysis dataset
analysis <- select(data1, one_of(keep_columns))
# Name - Shabbeer Hassan
# Date - 11 Nov 2018
# This is the week 2 work in the IODS course.
##### Read Data #####
data1 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt",
sep="\t", header=TRUE)
# Output from above
# str(data1)
# The output from above is the total number of observations (183 obs)
# and  total variables (n = 60)
# dim(data1)
# [1] 183  60
# The above tells us that data1 has 183 rows and 60 columns
##### Create an analysis dataset #####
library(dplyr)
# select the columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(data1, one_of(deep_questions))
data1$deep <- rowMeans(deep_columns)
# select the columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(data1, one_of(surface_questions))
data1$surf <- rowMeans(surface_columns)
# select the columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(data1, one_of(strategic_questions))
data1$stra <- rowMeans(strategic_columns)
# Choose the listed variables to keep
keep_columns <- c("gender","Age","attitude", "deep", "stra", "surf", "Points")
# Select the 'keep_columns' to create analysis dataset
analysis <- select(data1, one_of(keep_columns))
# Name - Shabbeer Hassan
# Date - 11 Nov 2018
# This is the week 2 work in the IODS course.
##### Read Data #####
data1 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt",
sep="\t", header=TRUE)
# Output from above
# str(data1)
# The output from above is the total number of observations (183 obs)
# and  total variables (n = 60)
# dim(data1)
# [1] 183  60
# The above tells us that data1 has 183 rows and 60 columns
##### Create an analysis dataset #####
library(dplyr)
# questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# select the columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(data1, one_of(deep_questions))
data1$deep <- rowMeans(deep_columns)
# select the columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(data1, one_of(surface_questions))
data1$surf <- rowMeans(surface_columns)
# select the columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(data1, one_of(strategic_questions))
data1$stra <- rowMeans(strategic_columns)
# Choose the listed variables to keep
keep_columns <- c("gender","Age","attitude", "deep", "stra", "surf", "Points")
# Select the 'keep_columns' to create analysis dataset
analysis <- select(data1, one_of(keep_columns))
# Name - Shabbeer Hassan
# Date - 11 Nov 2018
# This is the week 2 work in the IODS course.
##### Read Data #####
data1 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt",
sep="\t", header=TRUE)
# Output from above
# str(data1)
# The output from above is the total number of observations (183 obs)
# and  total variables (n = 60)
# dim(data1)
# [1] 183  60
# The above tells us that data1 has 183 rows and 60 columns
##### Create an analysis dataset #####
library(dplyr)
# questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# select the columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(data1, one_of(deep_questions))
data1$deep <- rowMeans(deep_columns)
# select the columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(data1, one_of(surface_questions))
data1$surf <- rowMeans(surface_columns)
# select the columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(data1, one_of(strategic_questions))
data1$stra <- rowMeans(strategic_columns)
# Choose the listed variables to keep
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
# Select the 'keep_columns' to create analysis dataset
analysis <- select(data1, one_of(keep_columns))
# create column 'attitude' by scaling the column "Attitude"
data1$attitude <- data1$Attitude / 10
# Name - Shabbeer Hassan
# Date - 11 Nov 2018
# This is the week 2 work in the IODS course.
##### Read Data #####
data1 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt",
sep="\t", header=TRUE)
# Output from above
# str(data1)
# The output from above is the total number of observations (183 obs)
# and  total variables (n = 60)
# dim(data1)
# [1] 183  60
# The above tells us that data1 has 183 rows and 60 columns
##### Create an analysis dataset #####
library(dplyr)
# Creating column 'attitude' by scaling the column "Attitude"
data1$attitude <- data1$Attitude / 10
# Questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# Select the columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(data1, one_of(deep_questions))
data1$deep <- rowMeans(deep_columns)
# Select the columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(data1, one_of(surface_questions))
data1$surf <- rowMeans(surface_columns)
# Select the columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(data1, one_of(strategic_questions))
data1$stra <- rowMeans(strategic_columns)
# Choose the listed variables to keep
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
# Select the 'keep_columns' to create analysis dataset
analysis <- select(data1, one_of(keep_columns))
analysis_final <- select(analysis, one_of("points" == 0))
analysis_final <- filter(analysis, points > 0)
# Name - Shabbeer Hassan
# Date - 11 Nov 2018
# This is the week 2 work in the IODS course.
##### Read Data #####
data1 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt",
sep="\t", header=TRUE)
# Output from above
# str(data1)
# The output from above is the total number of observations (183 obs)
# and  total variables (n = 60)
# dim(data1)
# [1] 183  60
# The above tells us that data1 has 183 rows and 60 columns
##### Create an analysis dataset #####
library(dplyr)
# Creating column 'attitude' by scaling the column "Attitude"
data1$attitude <- data1$Attitude / 10
# Questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# Select the columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(data1, one_of(deep_questions))
data1$deep <- rowMeans(deep_columns)
# Select the columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(data1, one_of(surface_questions))
data1$surf <- rowMeans(surface_columns)
# Select the columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(data1, one_of(strategic_questions))
data1$stra <- rowMeans(strategic_columns)
# Choose the listed variables to keep
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
# Select the 'keep_columns' to create analysis dataset
analysis <- select(data1, one_of(keep_columns))
View(analysis)
analysis_final <- filter(analysis, points == 0)
analysis_final <- filter(analysis, points = 0)
analysis_final <- filter(analysis, points == 0)
colnames(data1)
analysis_final <- filter(analysis, Points == 0)
View(analysis_final)
analysis_final <- filter(analysis, Points != 0)
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
# change the name of the second column
colnames(data1)[2] <- "age"
# change the name of "Points" to "points"
colnames(data1)[7] <- "points"
# Select the 'keep_columns' to create analysis dataset
analysis <- select(data1, one_of(keep_columns))
analysis$deep <- analysis$deep/mean(analysis$deep)
analysis$surf <- analysis$surf/mean(analysis$surf)
analysis$stra <- analysis$deep/mean(analysis$stra)
analysis_final <- filter(analysis, points != 0)
analysis_final <- filter(analysis, points != 0)
View(analysis)
# Name - Shabbeer Hassan
# Date - 11 Nov 2018
# This is the week 2 work in the IODS course.
##### Read Data #####
data1 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt",
sep="\t", header=TRUE)
# Output from above
# str(data1)
# The output from above is the total number of observations (183 obs)
# and  total variables (n = 60)
# dim(data1)
# [1] 183  60
# The above tells us that data1 has 183 rows and 60 columns
##### Create an analysis dataset #####
library(dplyr)
# Creating column 'attitude' by scaling the column "Attitude"
data1$attitude <- data1$Attitude / 10
# Questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# Select the columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(data1, one_of(deep_questions))
data1$deep <- rowMeans(deep_columns)
# Select the columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(data1, one_of(surface_questions))
data1$surf <- rowMeans(surface_columns)
# Select the columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(data1, one_of(strategic_questions))
data1$stra <- rowMeans(strategic_columns)
# Choose the listed variables to keep
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
# change the name of the second column
colnames(data1)[2] <- "age"
# change the name of "Points" to "points"
colnames(data1)[7] <- "points"
# Select the 'keep_columns' to create analysis dataset
analysis <- select(data1, one_of(keep_columns))
# Scale all combination variables to the original scales (by taking the mean).
# Exclude observations where the exam points variable is zero.
analysis$deep <- analysis$deep/mean(analysis$deep)
analysis$surf <- analysis$surf/mean(analysis$surf)
analysis$stra <- analysis$deep/mean(analysis$stra)
analysis <- filter(analysis, points != 0)
analysis <- filter(analysis, points != 0)
analysis <- filter(analysis, points > 0)
View(analysis)
# Name - Shabbeer Hassan
# Date - 11 Nov 2018
# This is the week 2 work in the IODS course.
##### Read Data #####
data1 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt",
sep="\t", header=TRUE)
# Output from above
# str(data1)
# The output from above is the total number of observations (183 obs)
# and  total variables (n = 60)
# dim(data1)
# [1] 183  60
# The above tells us that data1 has 183 rows and 60 columns
##### Create an analysis dataset #####
library(dplyr)
# Creating column 'attitude' by scaling the column "Attitude"
data1$attitude <- data1$Attitude / 10
# Questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# Select the columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(data1, one_of(deep_questions))
data1$deep <- rowMeans(deep_columns)
# Select the columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(data1, one_of(surface_questions))
data1$surf <- rowMeans(surface_columns)
# Select the columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(data1, one_of(strategic_questions))
data1$stra <- rowMeans(strategic_columns)
# Choose the listed variables to keep
keep_columns <- c("gender","Age","Attitude", "deep", "stra", "surf", "Points")
# Select the 'keep_columns' to create analysis dataset
analysis <- select(data1, one_of(keep_columns))
colnames(analysis)[c(2,7)] <- c("age", "points")
View(analysis)
View(analysis)
# Name - Shabbeer Hassan
# Date - 11 Nov 2018
# This is the week 2 work in the IODS course.
##### Read Data #####
data1 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt",
sep="\t", header=TRUE)
# Output from above
# str(data1)
# The output from above is the total number of observations (183 obs)
# and  total variables (n = 60)
# dim(data1)
# [1] 183  60
# The above tells us that data1 has 183 rows and 60 columns
##### Create an analysis dataset #####
library(dplyr)
# Creating column 'attitude' by scaling the column "Attitude"
data1$attitude <- data1$Attitude / 10
# Questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# Select the columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(data1, one_of(deep_questions))
data1$deep <- rowMeans(deep_columns)
# Select the columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(data1, one_of(surface_questions))
data1$surf <- rowMeans(surface_columns)
# Select the columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(data1, one_of(strategic_questions))
data1$stra <- rowMeans(strategic_columns)
# Choose the listed variables to keep
keep_columns <- c("gender", "Age", "Attitude", "deep", "stra", "surf", "Points")
# Select the 'keep_columns' to create analysis dataset
analysis <- select(data1, one_of(keep_columns))
# Change column names
colnames(analysis)[c(2, 3, 7)] <- c("age", "attitude", "points")
# Scale all combination variables to the original scales (by taking the mean).
# Exclude observations where the exam points variable is zero.
analysis$deep <- analysis$deep/mean(analysis$deep)
analysis$surf <- analysis$surf/mean(analysis$surf)
analysis$stra <- analysis$deep/mean(analysis$stra)
analysis <- filter(analysis, points > 0)
View(analysis)
?write.csv()
write.csv(analysis, learning2014.csv, col.names = TRUE)
write.csv(analysis, "~/Documents/GitHub/IODS/data/learning2014.csv"
, col.names = TRUE)
# Name - Shabbeer Hassan
# Date - 11 Nov 2018
# This is the week 2 work in the IODS course.
##### Read Data #####
data1 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt",
sep="\t", header=TRUE)
# Output from above
# str(data1)
# The output from above is the total number of observations (183 obs)
# and  total variables (n = 60)
# dim(data1)
# [1] 183  60
# The above tells us that data1 has 183 rows and 60 columns
##### Create an analysis dataset #####
library(dplyr)
# Creating column 'attitude' by scaling the column "Attitude"
data1$attitude <- data1$Attitude / 10
# Questions related to deep, surface and strategic learning
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
# Select the columns related to deep learning and create column 'deep' by averaging
deep_columns <- select(data1, one_of(deep_questions))
data1$deep <- rowMeans(deep_columns)
# Select the columns related to surface learning and create column 'surf' by averaging
surface_columns <- select(data1, one_of(surface_questions))
data1$surf <- rowMeans(surface_columns)
# Select the columns related to strategic learning and create column 'stra' by averaging
strategic_columns <- select(data1, one_of(strategic_questions))
data1$stra <- rowMeans(strategic_columns)
# Choose the listed variables to keep
keep_columns <- c("gender", "Age", "Attitude", "deep", "stra", "surf", "Points")
# Select the 'keep_columns' to create analysis dataset
analysis <- select(data1, one_of(keep_columns))
# Change column names
colnames(analysis)[c(2, 3, 7)] <- c("age", "attitude", "points")
# Scale all combination variables to the original scales (by taking the mean).
# Exclude observations where the exam points variable is zero.
analysis$deep <- analysis$deep/mean(analysis$deep)
analysis$surf <- analysis$surf/mean(analysis$surf)
analysis$stra <- analysis$deep/mean(analysis$stra)
analysis <- filter(analysis, points > 0)
#Set working directory
setwd("~/Documents/GitHub/IODS")
getwd()
write.csv(analysis, "~/Documents/GitHub/IODS/data/learning2014.csv"
, col.names = TRUE)
setwd("~/Documents/GitHub/IODS-project")
getwd()
write.csv(analysis, "~/Documents/GitHub/IODS-project/data/learning2014.csv"
, col.names = TRUE)
write.csv(analysis, "~/Documents/GitHub/IODS-project/data/learning2014.csv")
write.csv(analysis, "~/Documents/GitHub/IODS-project/data/learning2014.csv",
row.names = FALSE)
?read.csv
read_data <- read.csv("~/Documents/GitHub/IODS-project/data/learning2014.csv",
row.names = FALSE)
# Read the file above
read_data <- read.csv("~/Documents/GitHub/IODS-project/data/learning2014.csv")
View(read_data)
str(read_data)
dim(read_data)
data1 <- read.csv("~/Documents/GitHub/IODS-project/data/learning2014.csv",
sep="\t", header=TRUE)
View(analysis_final)
View(analysis)
data1 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt",
sep="\t", header=TRUE)
install.packages("GGally")
ggpairs(analysis_data, mapping = aes( col = gender, alpha = 0.3 ), lower = list(combo = wrap("facethist", bins = 20)))
library(GGally)
library(ggplot2)
ggpairs(analysis_data, mapping = aes( col = gender, alpha = 0.3 ), lower = list(combo = wrap("facethist", bins = 20)))
analysis_data <- read.csv("~/Documents/GitHub/IODS-project/data/learning2014.csv",
sep=",", header=TRUE)
ggpairs(analysis_data, mapping = aes( col = gender, alpha = 0.3 ), lower = list(combo = wrap("facethist", bins = 20)))
summary(analysis_data$gender)
summary(analysis_data$age)
summary(analysis_data$attitude)
summary(analysis_data$deep)
summary(analysis_data$stra)
summary(analysis_data$surf)
summary(analysis_data$points)
ggpairs(analysis_data, mapping = aes( col = gender, alpha = 0.3 ), lower = list(combo = wrap("facethist", bins = 20)))
ggpairs(analysis_data, mapping = aes( col = gender, alpha = 0.2 ), lower = list(combo = wrap("facethist", bins = 20)))
View(analysis)
View(analysis_data)
my_model <- lm(points ~ attitude + age + stra, data = analysis_data)
summary(my_model)
my_model2 <- lm(points ~  attitude, data = analysis_data)
summary(my_model2)
par(mfrow = c(2,2))
plot(my_model, which = c(1, 2, 5))
analysis_data_new <- analysis_data[-c(2, 4, 56), ]
my_model3 <- lm(points ~ attitude + age + stra, data = analysis_data_new)
summary(my_model3)
